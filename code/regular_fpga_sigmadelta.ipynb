{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGULAR NEURONS\n",
    "#14 neurons, connected to Poisson spikegen\n",
    "name_of_run= \"sigmadelta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import samna\n",
    "import samna.dynapse1 as dyn1\n",
    "import time\n",
    "\n",
    "import sys\n",
    "# change the path to '/home/class_NI2021/ctxctl_contrib' on zemo\n",
    "sys.path.insert(1, '/home/class_NI2021/ctxctl_contrib')\n",
    "from Dynapse1Constants import *\n",
    "import Dynapse1Utils as ut\n",
    "import NetworkGenerator as n\n",
    "from NetworkGenerator import Neuron\n",
    "import numpy as np\n",
    "from functions import find_max_time,find_min_time,isi_calc,interspike\n",
    "\n",
    "import matplotlib\n",
    "# Display plots inline, directly below the cell that produced it.\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "from numba import njit \n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "# open DYNAP-SE1 board to get Dynapse1Model\n",
    "device_name = \"my_dynapse1\"\n",
    "# change the port numbers to not have conflicts with other groups\n",
    "store = ut.open_dynapse1(device_name, gui=False, sender_port=119325, receiver_port=632943)\n",
    "model = getattr(store, device_name)\n",
    "\n",
    "np.random.seed(77)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings  \n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "\n",
    "def gen_param_group_1core():\n",
    "    paramGroup = dyn1.Dynapse1ParameterGroup()\n",
    "    # THR, gain factor of neurons\n",
    "    paramGroup.param_map[\"IF_THR_N\"].coarse_value = 5 #5\n",
    "    paramGroup.param_map[\"IF_THR_N\"].fine_value = 80\n",
    "\n",
    "    # refactory period of neurons\n",
    "    paramGroup.param_map[\"IF_RFR_N\"].coarse_value = 4\n",
    "    paramGroup.param_map[\"IF_RFR_N\"].fine_value = 128\n",
    "\n",
    "    # leakage of neurons\n",
    "    paramGroup.param_map[\"IF_TAU1_N\"].coarse_value = 4\n",
    "    paramGroup.param_map[\"IF_TAU1_N\"].fine_value = 80\n",
    "\n",
    "    # turn off tau2\n",
    "    paramGroup.param_map[\"IF_TAU2_N\"].coarse_value = 7\n",
    "    paramGroup.param_map[\"IF_TAU2_N\"].fine_value = 255\n",
    "\n",
    "    # turn off DC\n",
    "    paramGroup.param_map[\"IF_DC_P\"].coarse_value = 0\n",
    "    paramGroup.param_map[\"IF_DC_P\"].fine_value = 0\n",
    "\n",
    "    # leakage of AMPA\n",
    "    paramGroup.param_map[\"NPDPIE_TAU_F_P\"].coarse_value = 4\n",
    "    paramGroup.param_map[\"NPDPIE_TAU_F_P\"].fine_value = 80\n",
    "\n",
    "    # gain of AMPA\n",
    "    paramGroup.param_map[\"NPDPIE_THR_F_P\"].coarse_value = 4\n",
    "    paramGroup.param_map[\"NPDPIE_THR_F_P\"].fine_value = 80\n",
    "\n",
    "    # weight of AMPA\n",
    "    # NOTE: !!!!!!!!!!!!!!!!!!!!!!! remember to set the weight of AMPA !!!!!!!!!!!!!!!!!!!!!!!\n",
    "    paramGroup.param_map[\"PS_WEIGHT_EXC_F_N\"].coarse_value = 7\n",
    "    paramGroup.param_map[\"PS_WEIGHT_EXC_F_N\"].fine_value = 80 \n",
    "\n",
    "    # leakage of NMDA\n",
    "    paramGroup.param_map[\"NPDPIE_TAU_S_P\"].coarse_value = 4\n",
    "    paramGroup.param_map[\"NPDPIE_TAU_S_P\"].fine_value = 80\n",
    "\n",
    "    # gain of NMDA\n",
    "    paramGroup.param_map[\"NPDPIE_THR_S_P\"].coarse_value = 4\n",
    "    paramGroup.param_map[\"NPDPIE_THR_S_P\"].fine_value = 80\n",
    "\n",
    "    # weight of NMDA\n",
    "    paramGroup.param_map[\"PS_WEIGHT_EXC_S_N\"].coarse_value = 0\n",
    "    paramGroup.param_map[\"PS_WEIGHT_EXC_S_N\"].fine_value = 0\n",
    "\n",
    "    # leakage of GABA_A (shunting)\n",
    "    paramGroup.param_map[\"NPDPII_TAU_F_P\"].coarse_value = 4\n",
    "    paramGroup.param_map[\"NPDPII_TAU_F_P\"].fine_value = 80\n",
    "\n",
    "    # gain of GABA_A (shunting)\n",
    "    paramGroup.param_map[\"NPDPII_THR_F_P\"].coarse_value = 4\n",
    "    paramGroup.param_map[\"NPDPII_THR_F_P\"].fine_value = 80\n",
    "\n",
    "    # weight of GABA_A (shunting)\n",
    "    paramGroup.param_map[\"PS_WEIGHT_INH_F_N\"].coarse_value = 0\n",
    "    paramGroup.param_map[\"PS_WEIGHT_INH_F_N\"].fine_value = 0\n",
    "\n",
    "    # leakage of GABA_B\n",
    "    paramGroup.param_map[\"NPDPII_TAU_S_P\"].coarse_value = 2\n",
    "    paramGroup.param_map[\"NPDPII_TAU_S_P\"].fine_value = 80\n",
    "\n",
    "    # gain of GABA_B\n",
    "    paramGroup.param_map[\"NPDPII_THR_S_P\"].coarse_value = 4\n",
    "    paramGroup.param_map[\"NPDPII_THR_S_P\"].fine_value = 80\n",
    "\n",
    "    # weight of GABA_B\n",
    "    paramGroup.param_map[\"PS_WEIGHT_INH_S_N\"].coarse_value = 4\n",
    "    paramGroup.param_map[\"PS_WEIGHT_INH_S_N\"].fine_value = 80\n",
    "\n",
    "    # other advanced parameters\n",
    "    paramGroup.param_map[\"IF_NMDA_N\"].coarse_value = 0\n",
    "    paramGroup.param_map[\"IF_NMDA_N\"].fine_value = 0\n",
    "\n",
    "    #adaptation parameter 1/4\n",
    "    paramGroup.param_map[\"IF_AHTAU_N\"].coarse_value = 0\n",
    "    paramGroup.param_map[\"IF_AHTAU_N\"].fine_value = 0\n",
    "\n",
    "    #adaptation parameter 2/4\n",
    "    paramGroup.param_map[\"IF_AHTHR_N\"].coarse_value = 0 #0\n",
    "    paramGroup.param_map[\"IF_AHTHR_N\"].fine_value = 0 #0\n",
    "\n",
    "    #adaptation parameter 3/4\n",
    "    paramGroup.param_map[\"IF_AHW_P\"].coarse_value = 0 #0\n",
    "    paramGroup.param_map[\"IF_AHW_P\"].fine_value = 0 #0\n",
    "\n",
    "    #adaptation parameter 4/4\n",
    "    paramGroup.param_map[\"IF_CASC_N\"].coarse_value = 0 #0\n",
    "    paramGroup.param_map[\"IF_CASC_N\"].fine_value = 0 #0\n",
    "\n",
    "    paramGroup.param_map[\"PULSE_PWLK_P\"].coarse_value = 4\n",
    "    paramGroup.param_map[\"PULSE_PWLK_P\"].fine_value = 106\n",
    "\n",
    "    paramGroup.param_map[\"R2R_P\"].coarse_value = 3\n",
    "    paramGroup.param_map[\"R2R_P\"].fine_value = 85\n",
    "\n",
    "    paramGroup.param_map[\"IF_BUF_P\"].coarse_value = 3\n",
    "    paramGroup.param_map[\"IF_BUF_P\"].fine_value = 80\n",
    "\n",
    "    return paramGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# set initial (proper) parameters of 16 cores\n",
    "paramGroup = gen_param_group_1core()\n",
    "for chip in range(4):\n",
    "    for core in range(4):\n",
    "        model.update_parameter_group(paramGroup, chip, core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE NETWORK\n",
    "net_gen = n.NetworkGenerator()\n",
    "#net_gen.clear_network()\n",
    "\n",
    "\n",
    "spikegen_up = Neuron(0,0,1,True)\n",
    "spikegen_down = Neuron(0,0,2,True)\n",
    "\n",
    "# select the neurons\n",
    "chip_r = 0\n",
    "core_r = 0\n",
    "num_neurons_r = 14\n",
    "start_neuron_id_r = 16\n",
    "neuron_ids_r = []\n",
    "neurons_r = []\n",
    "\n",
    "for id in range(num_neurons_r):\n",
    "    neuron_ids_r.append((chip_r,core_r,start_neuron_id_r + id))\n",
    "print(\"Neuron for regular indexes:{}\".format(neuron_ids_r))\n",
    "\n",
    "for neuron_id in neuron_ids_r:\n",
    "    neurons_r.append(Neuron(neuron_id[0],neuron_id[1],neuron_id[2],False))\n",
    "\n",
    "\n",
    "#create synapses spikegen-neurons \n",
    "for i in range(14):\n",
    "    net_gen.add_connection(spikegen_up, neurons_r[i], dyn1.Dynapse1SynType.AMPA)\n",
    "\n",
    "\n",
    "for i in range(14):\n",
    "    net_gen.add_connection(spikegen_down, neurons_r[i], dyn1.Dynapse1SynType.GABA_B)\n",
    "#default was AMPA, should we change to NMDA? \n",
    "\n",
    "\n",
    "# print the network so you can double check (optional)\n",
    "net_gen.print_network()\n",
    "# make a dynapse1config using the network\n",
    "new_config = net_gen.make_dynapse1_configuration()\n",
    "# apply the configuration\n",
    "model.apply_configuration(new_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "#Firstly we define the head direciton signal.\n",
    "\n",
    "#Following the paper of Sadeghi et al., we construct a broadband noise stimuli characterized by a Gaussian \n",
    "#distribution of rotational velocities with mean = 0 and std = 20 degrees/s. The Signal is then low-pass filtered at \n",
    "#30 Hz.\n",
    "\n",
    "def gaussian_head_signal(mu, sigma, duration, freq):\n",
    "    \"\"\"\n",
    "    Generates a time series signal of a broadband noise signal characterized by a Gaussian distribution with a \n",
    "    certain mean and standard deviation, corresponding to angular velocity. Plots the signal in time\n",
    "    \n",
    "    Args: \n",
    "        mu (float): mean of the gaussian distribution\n",
    "        sigma (float): standard deviaiton of gaussian distribution\n",
    "        duration (np.ndarray): number of time points to sample (s)\n",
    "        freq (float): frequency boundary for low-pass filter\n",
    "        \n",
    "    Returns:\n",
    "            head_signal (np.ndarray): signal of head direction velocities generated by the gaussian\n",
    "            head_signal_filtered (np.ndarray): lowpass filtered head velocity signal\n",
    "            freq_signal_filtered (np.ndarray): lowpass filtered frequency signal\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = np.linspace(0, duration, int(duration*1e3)) \n",
    "    head_signal = np.random.normal(mu, sigma*(np.pi/180), int(duration*1e3))#np.random.normal(mu, sigma*(np.pi/180), int(duration*1e3))\n",
    "    \n",
    "    \n",
    "    sos = signal.butter(10, 30, 'lowpass', fs=1000, output='sos')\n",
    "    freq_signal_filtered = signal.sosfilt(sos, head_signal/(2*np.pi))\n",
    "    \n",
    "    \n",
    "    head_signal_filtered = freq_signal_filtered*(2*np.pi)*(180/np.pi)\n",
    "    \n",
    "    plt.figure(figsize=(8, 13))\n",
    "    \n",
    "    plt.subplot(211)\n",
    "    plt.plot(x, head_signal, color='tab:blue')\n",
    "    plt.title(\"Unfiltered head velocity stimulus\")\n",
    "    plt.xlabel(\"time (s)\")\n",
    "    plt.ylabel(\"rad/s\")\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.plot(x, head_signal_filtered, color='tab:orange')\n",
    "    plt.title(\"Filtered head velocity stimulus\")\n",
    "    plt.xlabel(\"time (s)\")\n",
    "    plt.ylabel(\"degrees/s\")\n",
    "    \n",
    "    #plt.subplot(224)\n",
    "    #plt.plot(x, freq_signal_filtered, color='tab:red')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return head_signal, head_signal_filtered, freq_signal_filtered\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigma delta modulator for the head direction signal\n",
    "from numba import njit \n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "#Usage:\n",
    "    #converts signal into UP and DOWN spikes using the Adaptive Delta Modulation scheme.\n",
    "    #spike times are determined through linear interpolation between the current and the next sampling point\n",
    "    \n",
    "#Input Parameters:\n",
    "    #input_signal (array): input signal\n",
    "    #threshold_UP (float): threshold for UP spikes to occur\n",
    "    #threshold_DOWN (float): threshold for DOWN spikes to occur\n",
    "    #sampling_frequency (float): sampling frequency of the input signal (1/dt)\n",
    "    #refractory_period_duration (float): refractory period in which spikes can not occur (NEEDS TO BE AT LEAST 1/sampling_frequency)\n",
    "    #return_indices (bool): if False, returns only spike times. If True, retuns a new time array along with UP and DOWN indices arrays which indicate when respective spikes occured\n",
    "    #index_dt (float): dt of ouput indices (for higher accuracy, use non-numba ADM as it will be faster)\n",
    "    #Vdc_reset (bool): determines whether signal continues to integrate in the refractory period (False)\n",
    "    #or whether the integration is reset and signal needs to integrate the full threshold after the refractory period (True)\n",
    "    \n",
    "#Output Parameters:\n",
    "    #spike_t_up (array): list of precise UP spike times\n",
    "    #spike_t_dn (array): list of precise DOWN spike times\n",
    "    #times_interpolated (array): time array for spike indices arrays (dt = index_dt)\n",
    "    #spike_idx_up (array of shape times_interpolated): closest times to UP spikes in times_interpolated are set to 1; rest is 0 \n",
    "    #spike_idx_dn (array of shape times_interpolated): closest times to DOWN spikes in times_interpolated are set to 1; rest is 0 \n",
    "    \n",
    "def ADM(input_signal,threshold_UP,threshold_DOWN,sampling_frequency,refractory_period_duration,return_indices = True,index_dt = 1e-4, Vdc_reset = True):\n",
    "    dt = 1/sampling_frequency\n",
    "    end_time = len(input_signal)*dt\n",
    "    times = np.linspace(0,end_time,len(input_signal))\n",
    "    if refractory_period_duration < dt:\n",
    "        interpolation_factor = 1\n",
    "        while dt > refractory_period_duration:\n",
    "            interpolation_factor += 1\n",
    "            dt = 1/(sampling_frequency*interpolation_factor)\n",
    "        f = interp1d(times, input_signal)\n",
    "        times = np.arange(0,times[-1],dt)\n",
    "        input_signal = f(times)\n",
    "        sampling_frequency = 1/times[1]\n",
    "    spike_t_up,spike_t_dn,times_interpolated,spike_idx_up,spike_idx_dn = ADM_numba(input_signal,threshold_UP,threshold_DOWN,sampling_frequency,refractory_period_duration,return_indices,index_dt, Vdc_reset)\n",
    "    return (spike_t_up,spike_t_dn,times_interpolated,spike_idx_up,spike_idx_dn)\n",
    "\n",
    "@njit(fastmath=True, parallel = True)\n",
    "def ADM_numba(input_signal,threshold_UP,threshold_DOWN,sampling_frequency,refractory_period_duration,return_indices = True,index_dt = 1e-4, Vdc_reset = True):\n",
    "\n",
    "    dt = 1/sampling_frequency\n",
    "    end_time = len(input_signal)*dt\n",
    "    times = np.linspace(0,end_time,len(input_signal)).astype(np.float64)\n",
    "    DC_Voltage = input_signal[0]\n",
    "    remainder_of_refractory = 0\n",
    "    spike_t_up = times[0:2]\n",
    "    spike_t_dn = times[0:2]\n",
    "    interpolate_from = 0.0\n",
    "    interpolation_activation = 0\n",
    "    intercept_point=0\n",
    "    for i,t in enumerate(times):\n",
    "        slope = ((input_signal[i]-input_signal[i-1])/dt)\n",
    "        if remainder_of_refractory > dt:\n",
    "            remainder_of_refractory = remainder_of_refractory-dt\n",
    "            interpolation_activation = 1\n",
    "            \n",
    "            if Vdc_reset:\n",
    "                DC_Voltage = (input_signal[i] - interpolate_from*slope)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            if interpolation_activation == 1:\n",
    "                interpolate_from = interpolate_from-remainder_of_refractory\n",
    "                Vbelow = (input_signal[i] - interpolate_from*slope)\n",
    "                DC_Voltage = Vbelow\n",
    "                \n",
    "                if DC_Voltage + threshold_UP < (input_signal[i] - interpolate_from*slope):\n",
    "                    spike_t_up = np.append(spike_t_up,t-interpolate_from)\n",
    "                    remainder_of_refractory = refractory_period_duration \n",
    "                    DC_Voltage = (input_signal[i] - interpolate_from*slope)\n",
    "                    interpolation_activation = 0\n",
    "                    continue\n",
    "\n",
    "                if DC_Voltage - threshold_DOWN > (input_signal[i] - interpolate_from*slope):\n",
    "                    spike_t_dn= np.append(spike_t_dn,t-interpolate_from)\n",
    "                    remainder_of_refractory = refractory_period_duration \n",
    "                    DC_Voltage = (input_signal[i] - interpolate_from*slope)\n",
    "                    interpolation_activation = 0\n",
    "                    continue\n",
    "                \n",
    "            else:\n",
    "                Vbelow = input_signal[i-1]\n",
    "                interpolate_from = dt\n",
    "\n",
    "            if DC_Voltage + threshold_UP <= input_signal[i]:\n",
    "                intercept_point = t-interpolate_from+((threshold_UP+DC_Voltage-Vbelow)/slope)\n",
    "                spike_t_up = np.append(spike_t_up,intercept_point)\n",
    "                interpolate_from = t+dt-intercept_point\n",
    "                remainder_of_refractory = refractory_period_duration \n",
    "                DC_Voltage = (input_signal[i] - interpolate_from*slope)\n",
    "\n",
    "            elif DC_Voltage - threshold_DOWN >= input_signal[i]:\n",
    "                intercept_point = t-interpolate_from+((-threshold_DOWN+DC_Voltage-Vbelow)/slope)\n",
    "                spike_t_dn = np.append(spike_t_dn,intercept_point)\n",
    "                interpolate_from = t+dt-intercept_point\n",
    "                remainder_of_refractory = refractory_period_duration \n",
    "                DC_Voltage = (input_signal[i] - interpolate_from*slope)\n",
    "\n",
    "            interpolation_activation = 0\n",
    "                        \n",
    "    index =[0,1]\n",
    "    spike_t_up = np.delete(spike_t_up, index)\n",
    "    spike_t_dn = np.delete(spike_t_dn, index)\n",
    "    if return_indices:\n",
    "        times_interpolated =   np.arange(0,end_time,index_dt)\n",
    "        spike_idx_up = np.zeros_like(times_interpolated)\n",
    "        spike_idx_dn = np.zeros_like(times_interpolated)\n",
    "        idxdn = np.searchsorted(times_interpolated,spike_t_dn)\n",
    "        spike_idx_dn[idxdn] = 1\n",
    "        idxup = np.searchsorted(times_interpolated,spike_t_up)\n",
    "        spike_idx_up[idxup] = 1\n",
    "    return (spike_t_up,spike_t_dn,times_interpolated,spike_idx_up,spike_idx_dn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now test on mu = 0 and std = 20 deg as stated in the paper\n",
    "mu = 0\n",
    "sigma = 20\n",
    "duration = 1\n",
    "freq = 30\n",
    "\n",
    "np.random.seed(77)\n",
    "head_signal, head_signal_filtered, freq_signal  = gaussian_head_signal(mu, sigma, duration, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_signal = head_signal_filtered*0.01\n",
    "threshold_UP = 0.03\n",
    "threshold_DOWN = 0.03\n",
    "dt = 1e-3\n",
    "sampling_frequency = 1/dt\n",
    "refractory_period_duration = 1/sampling_frequency\n",
    "\n",
    "spike_t_up, spike_t_down, times_interpolated,spike_idx_up, spike_idx_down =  ADM(input_signal,threshold_UP,threshold_DOWN,\n",
    "                                                  sampling_frequency,refractory_period_duration,\n",
    "                                                  return_indices = True,index_dt = 1e-3, Vdc_reset = True)\n",
    "\n",
    "plt.figure(figsize = (15,10))\n",
    "plt.plot(head_signal_filtered)\n",
    "plt.vlines(spike_t_down*1000, -1, 1, colors = \"g\",label = \"up spikes\")\n",
    "plt.vlines(spike_t_up*1000, -1, 1, colors = \"r\",label=\"down spikes\")\n",
    "plt.legend()\n",
    "#print(spike_t_down)\n",
    "#print(spike_t_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the fpga spike gen from Dynapse1Model\n",
    "#spike_t_up = spike_t_up.tolist()\n",
    "#print(spike_t_up.dtype)\n",
    "#s = np.array([0.10110785, 0.11072627 ,0.1183185 , 0.12491149, 0.13090515 ,0.136508])\n",
    "#s1 = spike_t_up[0:20]\n",
    "#s2 = np.linspace(0,5,320)\n",
    "\n",
    "#SPIKES UP\n",
    "fpga_spike_gen_up = model.get_fpga_spike_gen()\n",
    "\n",
    "spikegen_id = 1\n",
    "indices = [spikegen_id]*len(spike_t_up)\n",
    "\n",
    "post_chip = chip_r\n",
    "target_chips = [post_chip]*len(spike_t_up)\n",
    "\n",
    "# set up the fpga_spike_gen\n",
    "ut.set_fpga_spike_gen(fpga_spike_gen_up, spike_t_up , indices = indices, target_chips=target_chips, isi_base= 900, repeat_mode = False)\n",
    "\n",
    "#SPIKES DOWN\n",
    "fpga_spike_gen_down = model.get_fpga_spike_gen()\n",
    "\n",
    "spikegen_id = 2\n",
    "indices = [spikegen_id]*len(spike_t_down)\n",
    "\n",
    "post_chip = chip_r\n",
    "target_chips = [post_chip]*len(spike_t_down)\n",
    "\n",
    "# set up the fpga_spike_gen\n",
    "ut.set_fpga_spike_gen(fpga_spike_gen_down, spike_t_down , indices = indices, target_chips=target_chips, isi_base= 900, repeat_mode = False)\n",
    "\n",
    "\n",
    "\n",
    "#INDICES SET TO ONE OF THE PFGA, NEED TO CONNECT ALL TO ONE\n",
    "\n",
    "# remember to start the spikegen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#monitor neurons\n",
    "monitored_global_nids_r = ut.get_global_id_list(neuron_ids_r)\n",
    "\n",
    "#monitored_global_nids_r = [1]\n",
    "\n",
    "# create a graph to monitor the spikes of these neurons\n",
    "graph, filter_node, sink_node = ut.create_neuron_select_graph(model, monitored_global_nids_r)\n",
    "\n",
    "#1 second \n",
    "duration = 1\n",
    "\n",
    "# start monitor\n",
    "graph.start()\n",
    "\n",
    "# start the stimulus\n",
    "fpga_spike_gen_up.start()\n",
    "fpga_spike_gen_down.start()\n",
    "print(\"Starting Poisson spikegen for regular neurons\")\n",
    "#fpga_spike_gen.start()\n",
    "\n",
    "# ------------ get events -----------\n",
    "# clear the output buffer\n",
    "sink_node.get_buf()\n",
    "\n",
    "# sleep\n",
    "time.sleep(duration)\n",
    "\n",
    "# get the events accumulated during the past 2 sec\n",
    "events = sink_node.get_buf()\n",
    "\n",
    "# ------------ get events -----------\n",
    "\n",
    "# stop the stimulus\n",
    "fpga_spike_gen_up.stop()\n",
    "fpga_spike_gen_down.stop()\n",
    "print(\"Stopping Poisson spikegen for regular neurons\")\n",
    "\n",
    "# stop graph\n",
    "graph.stop()\n",
    "\n",
    "\n",
    "#timestamps of spikes\n",
    "timestamps = []\n",
    "frequencies = []\n",
    "\n",
    "for i in range(num_neurons_r):\n",
    "    neur_timestamps_id = i\n",
    "    timestamps_one_neuron = []\n",
    "    for evt in events:\n",
    "        if (evt.neuron_id-start_neuron_id_r) == neur_timestamps_id:\n",
    "            timestamps_one_neuron.append(evt.timestamp)\n",
    "\n",
    "    frequency_one_neuron = len(timestamps_one_neuron)/duration\n",
    "    print(\"Neuron {} timestamps: {}\".format(i,timestamps_one_neuron))\n",
    "    print(\"Spiking frequecy: {} Hz\".format(frequency_one_neuron))\n",
    "\n",
    "    timestamps.append(timestamps_one_neuron)\n",
    "    frequencies.append(frequency_one_neuron)\n",
    "'''\n",
    "#monitor spikegen\n",
    "spikegen_timestamps = []\n",
    "for evt in events:\n",
    "    spikegen_timestamps.append(evt.timestamp)\n",
    "\n",
    "print(\"spikegen timestamps:  {}\".format(spikegen_timestamps))\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_original = np.copy(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_time = find_min_time(timestamps_original)\n",
    "timestamps_preprocess = []\n",
    "timestamps_ms = []\n",
    "\n",
    "for timestamp in timestamps: \n",
    "    timestamps_preprocess.append(np.subtract(timestamp,min_time))\n",
    "    timestamps_ms.append(np.subtract(timestamp,min_time)/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(7,2, sharex=True,figsize=(15,50),facecolor=(1, 1, 1))  \n",
    "for i, ax in enumerate(axs.ravel()): \n",
    "    ax.set_title(\"Regular neuron #{}\".format(i)) \n",
    "    ax.hist(isi_calc(timestamps_ms[i]))\n",
    "    ax.xaxis.set_tick_params(labelbottom=True)\n",
    "    ax.set_xlabel(\"[ms]\")\n",
    "#plt.savefig(\"plots_regular/SDHistogram_{}.png\".format(name_of_run))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,10),facecolor=(1, 1, 1))\n",
    "plt.ylabel(\"Neuron index\")\n",
    "plt.title(\"Raster plot of regular neurons\")\n",
    "_ = plt.eventplot(timestamps_ms,linelengths=0.5)\n",
    "#plt.savefig(\"plots_regular/SDRaster_{}.png\".format(name_of_run))\n",
    "\n",
    "\n",
    "plt.figure(facecolor=(1, 1, 1))\n",
    "plt.plot(frequencies)\n",
    "plt.title(\"Frequencies of firing\")\n",
    "plt.xlabel(\"Neuron nr.\")\n",
    "plt.ylabel(\"Frequency [Hz]\")\n",
    "plt.ylim(0,100)\n",
    "#plt.savefig(\"plots_regular/SDFrequencies_{}.png\".format(name_of_run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close Dynapse1\n",
    "#ut.close_dynapse1(store, device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_signal(signal, recording_duration):\n",
    "    \"\"\"\n",
    "    Given a spike train with the spike times, create a binary signal of spikes\n",
    "    \n",
    "    Args:\n",
    "        signal (np.ndarray): array of spike times\n",
    "        recording_duration (float): duration of time the recording has lasted in ms\n",
    "        \n",
    "    Returns: \n",
    "            bsignal (np.ndarray): time series of binary signal\n",
    "    \"\"\"\n",
    "    bsignal = np.zeros((recording_duration,))\n",
    "    bsignal[signal] = 1\n",
    "    \n",
    "    return bsignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we recorded the signal for 1000 micro s\n",
    "recording_duration = 1000\n",
    "\n",
    "#as a trial we will use the 0th neuron timestamp\n",
    "\n",
    "spike_response = timestamps_ms[0]\n",
    "\n",
    "#Now we wish to plot the spiking response inverted and non-inverted.\n",
    "\n",
    "response = binary_signal(np.round(spike_response).astype(int),recording_duration)\n",
    "response_flipped = binary_signal(np.round(-spike_response).astype(int),recording_duration)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(response)\n",
    "plt.title(\"Binary spiking signal\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(response_flipped)\n",
    "plt.title(\"Binary inverted spiking signal\")\n",
    "\n",
    "plt.figure()\n",
    "stimuli = binary_signal((spikes).astype(int), recording_duration)\n",
    "plt.plot(stimuli)\n",
    "plt.title(\"Input spikes\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_signal(response, response_flipped, stimuli):\n",
    "    \"\"\"\n",
    "    Reconstructs the signal as shown in the neural variability paper, by convolving the spike train resposne with the\n",
    "    kernel that minimizes the MSE.\n",
    "    \n",
    "    Args:\n",
    "        response(np.ndarray): binary array contining the spikes\n",
    "        response_flipped (np.ndarray): the flipped spike times (multiplied by -1)\n",
    "        stimuli (np.ndarray): initial binary spike times\n",
    "    \n",
    "    Returns:\n",
    "            signal_estimate(np.ndarray): vaues of the reconstructed signal esitmate\n",
    "    \"\"\"\n",
    "\n",
    "    #Computes the stimulus-response cross spectrum (the functio takes the fourier transform of the signal)\n",
    "    f_rs, Prs = signal.csd(response_flipped,stimuli,scaling = \"spectrum\", nperseg = 1000)\n",
    "    plt.semilogy(f_rs, Prs)\n",
    "    plt.plot()\n",
    "    plt.title(\"Stimulus-response cross spectrum\")\n",
    "\n",
    "    \n",
    "    #Computes the power spectrum of the response: note that when using the welch function, very different results are\n",
    "    #observed. Uncomment it and comment out the periodgram to see.\n",
    "    \n",
    "    f_rr, Prr = signal.welch(response, nperseg=1000)  \n",
    "    #f_rr, Prr = signal.periodogram(response,scaling = \"spectrum\")\n",
    "    plt.figure()\n",
    "    plt.semilogy(f_rr, Prr)\n",
    "    plt.title(\"Output response power-spectrum\")\n",
    "\n",
    "    #Kernel in the fourier domain that minimizes the MSE\n",
    "    K_fourier = Prs / Prr\n",
    "    \n",
    "    K_fourier_real = K_fourier.real\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(K_fourier)\n",
    "    plt.title(\"Fourier transform of the kernel\")\n",
    "    \n",
    "    #Inverting the fourier transform to get the kernel for the convolution\n",
    "    kernel = np.fft.ifft(K_fourier_real)\n",
    "    kernel_real = np.real(kernel)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(kernel)\n",
    "    plt.plot(kernel_real)\n",
    "    plt.title(\"Reconstruction kernel\")\n",
    "\n",
    "    #signal estimate by convolving the spike responses with the kernal\n",
    "    signal_estimate = np.convolve(response, kernel_real)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(signal_estimate)\n",
    "    plt.title(\"Signal reconstruction\")\n",
    "    \n",
    "    return signal_estimate, K_fourier_real, kernel, kernel_real\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal_reconstructed, K_fourier, kernel, kernel_real = reconstruct_signal(response, response_flipped, stimuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "gauss = scipy.signal.gaussian(1000, 8, sym=True)\n",
    "plt.plot(gauss)\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlabel(\"Time [ms]\")\n",
    "\n",
    "print(gauss.shape)\n",
    "recon = np.convolve(gauss,response)\n",
    "plt.figure()\n",
    "plt.plot(recon[0:1501])\n",
    "plt.xlabel(\"Time [ms]\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "#plt.figure()\n",
    "#plt.plot(response)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(head_signal_filtered)\n",
    "plt.xlabel(\"Time [ms]\")\n",
    "plt.ylabel(\"Amplitude (deg/s)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular correlation for neuron 0\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr, _ = pearsonr(recon[500:1500], head_signal_filtered)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(signal, a, b):\n",
    "      # solving system of linear equations one can find the coefficients\n",
    "      A = np.min(signal)\n",
    "      B = np.max(signal)\n",
    "      C = (a-b)/(A-B)\n",
    "      k = (C*A - a)/C\n",
    "      return (signal-k)*C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regular neuron normalized correlation with shift\n",
    "\n",
    "h_n = normalize(head_signal_filtered, -1, 1)\n",
    "r_n = normalize(recon[480:1480], -1, 1)\n",
    "\n",
    "corr_n, _ = pearsonr(r_n, h_n)\n",
    "print(corr_n)\n",
    "\n",
    "plt.plot(h_n, label = \"head velocity stimulus\")\n",
    "plt.plot(r_n, label = \"stimulus reconstruction\")\n",
    "plt.title(\"Normalized plots of stimulus and output\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Normalized head velocity amplitude\")\n",
    "plt.legend(loc = \"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coherence(stimulus, output):\n",
    "    \"\"\"\n",
    "    Calculates the coherence of the stimulus and the output of the neurons\n",
    "    \n",
    "    Args:\n",
    "        stimulus (np.ndarray): time series stimulus\n",
    "        output (np.ndarray): time series output of neuron\n",
    "        \n",
    "    Return:\n",
    "            coherence (np.ndarray): value of coherence of output and stimulus signal for different frequency values\n",
    "    \"\"\"\n",
    "    #Calculate the stimulus-response cross spectrum\n",
    "    frs, Prs = signal.csd(stimulus, output, nperseg = 1000)\n",
    "    \n",
    "    #Power spectrum of the spike train (output)\n",
    "    #frr, Prr = signal.welch(output)\n",
    "    \n",
    "    frr, Prr = signal.periodogram(output)\n",
    "    \n",
    "    #Power spectrum of the stimulus\n",
    "    #fss, Pss = signal.welch(stimulus)\n",
    "    \n",
    "    fss, Pss = signal.periodogram(stimulus)\n",
    "    \n",
    "    Cf = (np.abs(Prs)**2)/(Prr*Pss) #coherence values\n",
    "    \n",
    "    \n",
    "    \n",
    "    return Cf, frs, frr, fss, Prs, Pss, Prr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cf, frs, frr, fss, Prs, Pss, Prr= coherence(h_n, r_n)\n",
    "print(\"Mean coherence of stimulus and output is\", np.mean(Cf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#spike sorting by up and down\n",
    "import numpy as np\n",
    "spikes = np.arange(7)\n",
    "up_spikes = spikes[0:2]\n",
    "down_spikes = spikes[2:]\n",
    "\n",
    "#up spikes have index of 1\n",
    "ones = np.ones(up_spikes.shape)\n",
    "\n",
    "#down spikes have index 2\n",
    "twos = 2*np.ones(down_spikes.shape)\n",
    "\n",
    "indx_concatenate = np.concatenate((ones, twos))\n",
    "\n",
    "spikes_concatenate = np.concatenate((up_spikes, down_spikes))\n",
    "\n",
    "sorted_idx_spike = np.argsort(spikes_concatenate)\n",
    "\n",
    "sorted_idx_spikegen = indx_concatenate[sorted_idx_spike]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_idx_spike)\n",
    "print(sorted_idx_spikegen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.array([1, 2])\n",
    "neg = np.array([-2, -1])\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "corr, _ = pearsonr(pos, neg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
